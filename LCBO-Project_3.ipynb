{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bf9afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "browser = Browser('chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ea4667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the web page\n",
    "url = \"https://www.lcbo.com/en/products#t=clp-products&sort=relevancy&layout=card&f:@lcbo_current_offer=[On%20Sale]\"\n",
    "browser.visit(url)\n",
    "\n",
    "html = browser.html\n",
    "soup=BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7dfe82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select \"English\" as preffered language\n",
    "time.sleep(3)\n",
    "results = browser.links.find_by_text('English')\n",
    "results.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "630879b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #: 1\n",
      "Iteration #: 2\n"
     ]
    }
   ],
   "source": [
    "# This is for loading more products \n",
    "max_iteration = 1\n",
    "iteration = 0\n",
    "\n",
    "while iteration<= max_iteration:\n",
    "    # Extract the HTML of the current page\n",
    "    html = browser.html\n",
    "    \n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    all_links = soup.find_all(\"div\", class_ = 'coveo-product-items')\n",
    "\n",
    "    links = []\n",
    "    \n",
    "    for link in all_links:\n",
    "        results = link.a['href']\n",
    "        links.append(results)\n",
    "        \n",
    "    # Find the element by ID\n",
    "    element = soup.find(id='loadMore')\n",
    "    \n",
    "    if element is None:\n",
    "        # Element not found, exit the loop\n",
    "        break\n",
    "        \n",
    "    # Wait for 2 seconds\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Click on the element\n",
    "    browser.find_by_id('loadMore').click()\n",
    "    \n",
    "    \n",
    "    \n",
    "    iteration += 1\n",
    "    \n",
    "    print(f'Iteration #: {iteration}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7f6c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dab256df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "regular_price = []\n",
    "sale_price = []\n",
    "name = []\n",
    "rating = []\n",
    "onsale = [] #this is the On Sale tag\n",
    "reviews = []\n",
    "size = []\n",
    "description = []\n",
    "category = []\n",
    "details_dictionary = {}\n",
    "\n",
    "max_iteration2 = 4\n",
    "iteration2 = 0\n",
    "\n",
    "while iteration2 <= max_iteration2:\n",
    "    for record in links:\n",
    "        url = record\n",
    "        browser.visit(url)\n",
    "        html = browser.html\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "    #     results = browser.links.find_by_text('English')\n",
    "    #     results.click()\n",
    "\n",
    "        old_price = soup.find('span', class_ = 'old-price')\n",
    "        old = old_price.find('span', class_ = 'price')\n",
    "        regular_price.append(old.find('span', class_ = 'price').text)\n",
    "\n",
    "        on_sale_price = soup.find('span', class_ = 'special-price')\n",
    "        new_price = on_sale_price.find('span', class_ = 'price')\n",
    "        sale_price.append(new_price.find('span', class_ = 'price').text)\n",
    "\n",
    "        name.append(soup.find('div', class_ = 'page-title-wrapper').text)\n",
    "        onsale.append(soup.find('div', class_ = 'amlabel-text').text)\n",
    "        try:\n",
    "            rating.append(soup.find('div', class_ = 'bv_avgRating_component_container notranslate').text)\n",
    "        except AttributeError:\n",
    "            rating.append('N/A')\n",
    "        reviews.append(soup.find('div', class_ = 'bv_numReviews_text').text)\n",
    "        size.append(soup.find('div', class_ = 'lcbo-product-size').text)\n",
    "        description.append(soup.find('div', class_ = 'testing_note').text)\n",
    "\n",
    "        categories_all = soup.find('div', class_ = 'breadcrumbs')\n",
    "        categories = categories_all.find_all('li', class_ = 'item')\n",
    "        category_list = []\n",
    "\n",
    "        for category_record in categories:\n",
    "            category_list.append(category_record.text)\n",
    "        category = category_list[-2]\n",
    "\n",
    "        moredetail = soup.find('div', class_ = 'moredetail')\n",
    "        all_details = moredetail.find_all('li')\n",
    "        details = {}\n",
    "        \n",
    "        for detail_record in all_details:\n",
    "            details_value = detail_record.find('div', class_ = 'value').text\n",
    "            details_name = detail_record.find('div', class_ = 'label').text\n",
    "            details[details_name] = details_value\n",
    "        \n",
    "        details_dictionary['details'] = details\n",
    "        \n",
    "        iteration2 += 1\n",
    "        \n",
    "        print(iteration2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93d2f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_price = soup.find('span', class_ = 'old-price')\n",
    "# old = old_price.find('span', class_ = 'price')\n",
    "# regular_price = old.find('span', class_ = 'price').text\n",
    "\n",
    "# sale_price = soup.find('span', class_ = 'special-price')\n",
    "# new_price = sale_price.find('span', class_ = 'price')\n",
    "# onsale = new_price.find('span', class_ = 'price').text\n",
    "\n",
    "# name = soup.find('div', class_ = 'page-title-wrapper').text\n",
    "# onsale = soup.find('div', class_ = 'amlabel-text').text\n",
    "# rating = soup.find('div', class_ = 'bv_avgRating_component_container notranslate').text\n",
    "# reviews = soup.find('div', class_ = 'bv_numReviews_text').text\n",
    "# size = soup.find('div', class_ = 'lcbo-product-size').text\n",
    "# description = soup.find('div', class_ = 'testing_note').text\n",
    "\n",
    "# categories_all = soup.find('div', class_ = 'breadcrumbs')\n",
    "# categories = categories_all.find_all('li', class_ = 'item')\n",
    "# category_list = []\n",
    "# for record in categories:\n",
    "#     category_list.append(record.text)\n",
    "# category = category_list[-2]\n",
    "\n",
    "# moredetail = soup.find('div', class_ = 'moredetail')\n",
    "# all_details = moredetail.find_all('li')\n",
    "# len_details = len(all_details)\n",
    "# details = {}\n",
    "\n",
    "# for record in all_details:\n",
    "#     details_value = record.find('div', class_ = 'value').text\n",
    "#     details_name = record.find('div', class_ = 'label').text\n",
    "#     details[details_name] = details_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "930de2b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mixing dicts with non-Series may lead to ambiguous ordering.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22928\\3342524858.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Create a dataframe from the data dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m# Display the dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    678\u001b[0m                     \u001b[1;34m\"Mixing dicts with non-Series may lead to ambiguous ordering.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m                 )\n",
      "\u001b[1;31mValueError\u001b[0m: Mixing dicts with non-Series may lead to ambiguous ordering."
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Name': name,\n",
    "    'Regular Price': regular_price,\n",
    "    'Sale Price': sale_price,\n",
    "    'Rating': rating,\n",
    "    'Reviews': reviews,\n",
    "    'Size': size,\n",
    "    'Description': description,\n",
    "    'Category': category,\n",
    "}\n",
    "\n",
    "# regular_price = [] ok\n",
    "# sale_price = [] ok\n",
    "# name = [] ok\n",
    "# rating = [] ok\n",
    "# reviews = [] ok\n",
    "# size = [] ok\n",
    "# description = [] ok\n",
    "# category = [] ok \n",
    "\n",
    "# details = {}\n",
    "# # Add the details dictionary to the data dictionary\n",
    "data.update(details_dictionary)\n",
    "\n",
    "# Create a dataframe from the data dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the dataframe\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56221dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Home', 'Products', 'Wine', 'Red Wine', 'Yellow Tail Shiraz']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "082bf81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_all = soup.find('div', class_ = 'breadcrumbs')\n",
    "categories = categories_all.find_all('li', class_ = 'item')\n",
    "\n",
    "category_list1 = []\n",
    "    \n",
    "for category_record in categories:\n",
    "        category_list1.append(category_record.text)\n",
    "        category_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c9d49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
